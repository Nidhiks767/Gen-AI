{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veRp2nfSsxyl",
        "outputId": "dc519c1e-16e4-4ffa-eeb9-b89abd01dd03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-1.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install groq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=\"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\")\n",
        "\n",
        "def run_prompt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "kqc4hdJhs0ql"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persona_prompt = \"\"\"\n",
        "Act as a Senior Software Engineer with 10+ years of experience in backend development.\n",
        "\n",
        "Task:\n",
        "Explain REST APIs in simple terms and give a small Python example.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "oSmcyhIQtCls"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Persona Prompting Output:\\n\")\n",
        "print(run_prompt(persona_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE2r63uLtFIY",
        "outputId": "b6c654aa-8314-4be6-df52-86ea197b0023"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Persona Prompting Output:\n",
            "\n",
            "**What are REST APIs?**\n",
            "\n",
            "REST (Representational State of Resource) APIs are a way to communicate between different systems over the internet. They are based on the idea of resources, which can be thought of as objects or data that can be manipulated.\n",
            "\n",
            "Think of a REST API like a library catalog system. You can perform actions on the catalog, such as:\n",
            "\n",
            "* Retrieving a list of books (GET /books)\n",
            "* Creating a new book (POST /books)\n",
            "* Updating an existing book (PUT /books/{id})\n",
            "* Deleting a book (DELETE /books/{id})\n",
            "\n",
            "Each action is represented by a specific HTTP method (GET, POST, PUT, DELETE) and a URL that identifies the resource.\n",
            "\n",
            "**Key Concepts:**\n",
            "\n",
            "* **Resources:** These are the objects or data that can be manipulated. Examples: books, users, orders.\n",
            "* **HTTP Methods:** These are the actions that can be performed on resources. Examples: GET, POST, PUT, DELETE.\n",
            "* **URLs:** These identify the resources and are used to perform actions on them.\n",
            "\n",
            "**Example in Python using Flask**\n",
            "\n",
            "Here's a simple example of a REST API using Flask, a popular Python web framework.\n",
            "\n",
            "```python\n",
            "from flask import Flask, jsonify, request\n",
            "\n",
            "app = Flask(__name__)\n",
            "\n",
            "# Sample data\n",
            "books = [\n",
            "    {\"id\": 1, \"title\": \"Book 1\", \"author\": \"Author 1\"},\n",
            "    {\"id\": 2, \"title\": \"Book 2\", \"author\": \"Author 2\"}\n",
            "]\n",
            "\n",
            "# GET /books\n",
            "@app.route('/books', methods=['GET'])\n",
            "def get_books():\n",
            "    return jsonify(books)\n",
            "\n",
            "# GET /books/{id}\n",
            "@app.route('/books/<int:id>', methods=['GET'])\n",
            "def get_book(id):\n",
            "    book = next((book for book in books if book['id'] == id), None)\n",
            "    if book:\n",
            "        return jsonify(book)\n",
            "    return jsonify({\"error\": \"Book not found\"}), 404\n",
            "\n",
            "# POST /books\n",
            "@app.route('/books', methods=['POST'])\n",
            "def create_book():\n",
            "    new_book = {\n",
            "        \"id\": len(books) + 1,\n",
            "        \"title\": request.json['title'],\n",
            "        \"author\": request.json['author']\n",
            "    }\n",
            "    books.append(new_book)\n",
            "    return jsonify(new_book), 201\n",
            "\n",
            "# PUT /books/{id}\n",
            "@app.route('/books/<int:id>', methods=['PUT'])\n",
            "def update_book(id):\n",
            "    book = next((book for book in books if book['id'] == id), None)\n",
            "    if book:\n",
            "        book['title'] = request.json['title']\n",
            "        book['author'] = request.json['author']\n",
            "        return jsonify(book)\n",
            "    return jsonify({\"error\": \"Book not found\"}), 404\n",
            "\n",
            "# DELETE /books/{id}\n",
            "@app.route('/books/<int:id>', methods=['DELETE'])\n",
            "def delete_book(id):\n",
            "    global books\n",
            "    books = [book for book in books if book['id'] != id]\n",
            "    return jsonify({\"message\": \"Book deleted\"})\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    app.run(debug=True)\n",
            "```\n",
            "\n",
            "This example demonstrates the following REST API endpoints:\n",
            "\n",
            "* `GET /books`: Retrieves a list of all books.\n",
            "* `GET /books/{id}`: Retrieves a specific book by ID.\n",
            "* `POST /books`: Creates a new book.\n",
            "* `PUT /books/{id}`: Updates an existing book.\n",
            "* `DELETE /books/{id}`: Deletes a book.\n",
            "\n",
            "Note that this is a simplified example and you should consider implementing authentication, authorization, and error handling in a real-world application.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cognitive_verifier_prompt = \"\"\"\n",
        "Act as an AI research assistant.\n",
        "\n",
        "Main Question:\n",
        "How does Retrieval-Augmented Generation (RAG) work?\n",
        "\n",
        "Instructions:\n",
        "1. First, list the sub-questions that must be answered to verify correctness.\n",
        "2. Then provide the final clear answer.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "9oa9oTvntJWr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCognitive Verifier Output:\\n\")\n",
        "print(run_prompt(cognitive_verifier_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJtx6EbWt40i",
        "outputId": "8e59f915-c604-4dd5-de6e-34a9d32efae8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cognitive Verifier Output:\n",
            "\n",
            "I'd be happy to help you understand Retrieval-Augmented Generation (RAG). To verify the correctness of the explanation, I'll first list the sub-questions that need to be answered:\n",
            "\n",
            "**Sub-questions:**\n",
            "\n",
            "1. What is Retrieval-Augmented Generation (RAG)?\n",
            "2. How does RAG differ from traditional Generative Models?\n",
            "3. What is the role of the Retrieval Component in RAG?\n",
            "4. How does the Generation Component interact with the Retrieval Component?\n",
            "5. What are the key benefits of using RAG over traditional Generative Models?\n",
            "\n",
            "**Answer:**\n",
            "\n",
            "Retrieval-Augmented Generation (RAG) is a type of Generative Model that combines the strengths of Retrieval-based and Generative-based approaches. RAG consists of two main components: a Retrieval Component and a Generation Component.\n",
            "\n",
            "**Retrieval Component:**\n",
            "The Retrieval Component is responsible for retrieving relevant information from a large corpus of text. This component uses a similarity metric (e.g., cosine similarity) to match the input query with the most relevant documents in the corpus. The retrieved documents are then used as input to the Generation Component.\n",
            "\n",
            "**Generation Component:**\n",
            "The Generation Component is responsible for generating text based on the input query and the retrieved documents. This component uses a Generative Model (e.g., Transformer) to generate text that is conditioned on the input query and the retrieved documents.\n",
            "\n",
            "**Interaction between Components:**\n",
            "The Retrieval Component and the Generation Component interact in the following way: the Retrieval Component retrieves relevant documents based on the input query, and the Generation Component generates text based on the input query and the retrieved documents.\n",
            "\n",
            "**Key Benefits:**\n",
            "RAG has several key benefits over traditional Generative Models, including:\n",
            "\n",
            "* Improved accuracy: RAG can generate more accurate text by leveraging the relevant information retrieved from the corpus.\n",
            "* Reduced hallucination: RAG can reduce the likelihood of hallucination (i.e., generating text that is not supported by the input query) by relying on the retrieved documents.\n",
            "* Increased flexibility: RAG can be used for a wide range of tasks, including text summarization, question answering, and text classification.\n",
            "\n",
            "In summary, Retrieval-Augmented Generation (RAG) is a type of Generative Model that combines the strengths of Retrieval-based and Generative-based approaches to generate high-quality text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_refinement_prompt = \"\"\"\n",
        "Original Question:\n",
        "\"Explain machine learning.\"\n",
        "\n",
        "Task:\n",
        "Suggest a more precise and effective version of this question to get a better answer.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "i6oE-6uXt6xE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nQuestion Refinement Output:\\n\")\n",
        "print(run_prompt(question_refinement_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvg0wLx3t-5p",
        "outputId": "b27180ad-407d-4326-ddbd-7e4d5a1b2840"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question Refinement Output:\n",
            "\n",
            "A more precise and effective version of the question could be:\n",
            "\n",
            "\"What are the key concepts and subfields of machine learning, and how do they enable computers to learn from data and make predictions or decisions?\"\n",
            "\n",
            "This revised question:\n",
            "\n",
            "1. Shows that you have a basic understanding of machine learning and are looking for more specific information.\n",
            "2. Provides a clear direction for the answer, allowing the respondent to focus on the key concepts and subfields.\n",
            "3. Highlights the core capabilities of machine learning, which are learning from data and making predictions or decisions.\n",
            "\n",
            "Alternatively, you could also ask:\n",
            "\n",
            "* \"Can you explain the differences between supervised, unsupervised, and reinforcement learning?\"\n",
            "* \"How do neural networks and deep learning contribute to machine learning?\"\n",
            "* \"What are some real-world applications of machine learning, and how do they work?\"\n",
            "\n",
            "These questions demonstrate a more specific understanding of machine learning and can lead to more detailed and effective answers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_info_prompt = \"\"\"\n",
        "Information:\n",
        "Retrieval-Augmented Generation (RAG) combines a document retriever with a language model.\n",
        "The retriever fetches relevant documents, and the generator produces answers using both\n",
        "the query and retrieved documents.\n",
        "\n",
        "Task:\n",
        "Based ONLY on the above information, ask three questions to test my understanding.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "ivDJ2QG3uAb0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nProvide New Information & Ask Questions Output:\\n\")\n",
        "print(run_prompt(new_info_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTnvHVSHuCqD",
        "outputId": "c5f2f825-73ea-4663-89ac-b5f3c2bc444f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Provide New Information & Ask Questions Output:\n",
            "\n",
            "Here are three questions to test your understanding of Retrieval-Augmented Generation (RAG):\n",
            "\n",
            "1. What are the two primary components that make up a Retrieval-Augmented Generation (RAG) model?\n",
            "\n",
            "2. What is the primary function of the document retriever in a RAG model?\n",
            "\n",
            "3. What information does the generator in a RAG model use to produce answers?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_prompt = \"\"\"\n",
        "ROOT INSTRUCTION:\n",
        "You are an academic teaching assistant.\n",
        "Only provide concise, exam-oriented answers.\n",
        "Do not add extra explanations or assumptions.\n",
        "\n",
        "Task:\n",
        "Explain Prompt Engineering in 5 bullet points.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "PPzOAAKxuEXH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRoot Prompt Output:\\n\")\n",
        "print(run_prompt(root_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zY3zW6GuGkF",
        "outputId": "eae93f8f-6376-4067-c258-918320bb3cc2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Root Prompt Output:\n",
            "\n",
            "Here are 5 key points about Prompt Engineering:\n",
            "\n",
            "• **Definition**: Prompt Engineering is the process of designing and optimizing input prompts to elicit specific, accurate, and relevant responses from language models.\n",
            "\n",
            "• **Goals**: Improve model performance, reduce ambiguity, and increase the likelihood of obtaining the desired output.\n",
            "\n",
            "• **Key components**: Understanding model capabilities, identifying bias and errors, and crafting effective prompts that minimize ambiguity and maximize relevance.\n",
            "\n",
            "• **Techniques**: Using specific keywords, providing context, asking follow-up questions, and employing active voice to elicit desired responses.\n",
            "\n",
            "• **Applications**: Enhancing conversational AI, improving question-answering systems, and optimizing language translation models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cot_prompt = \"\"\"\n",
        "Question:\n",
        "If a laptop costs 50,000 rupees and a discount of 10% is applied, what is the final price?\n",
        "\n",
        "Let's think step-by-step.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "DT1i2uEjuIQr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Chain of Thought Output:\\n\")\n",
        "print(run_prompt(cot_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3pcElN5vakX",
        "outputId": "3d6c9464-6da0-4824-eb14-0084bed3d301"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain of Thought Output:\n",
            "\n",
            "To find the final price after applying a 10% discount, we'll follow these steps:\n",
            "\n",
            "1. Calculate the discount amount: \n",
            "   Discount percentage = 10%\n",
            "   Discount amount = 10% of 50,000 rupees\n",
            "   Discount amount = (10/100) * 50,000\n",
            "   Discount amount = 0.1 * 50,000\n",
            "   Discount amount = 5,000 rupees\n",
            "\n",
            "2. Subtract the discount amount from the original price:\n",
            "   Original price = 50,000 rupees\n",
            "   Discount amount = 5,000 rupees\n",
            "   Final price = Original price - Discount amount\n",
            "   Final price = 50,000 - 5,000\n",
            "   Final price = 45,000 rupees\n",
            "\n",
            "So, the final price of the laptop after applying a 10% discount is 45,000 rupees.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tabular_prompt = \"\"\"\n",
        "Provide the differences between Supervised and Unsupervised Learning.\n",
        "Provide the results in a markdown table with headers:\n",
        "Algorithm Type | Uses Labeled Data | Example Algorithms\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "ENPoCSKFvcYz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTabular Format Output:\\n\")\n",
        "print(run_prompt(tabular_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksviqFZ6venT",
        "outputId": "391ecda6-20be-483d-e86a-83a2aa68139b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tabular Format Output:\n",
            "\n",
            "**Supervised Learning vs Unsupervised Learning**\n",
            "\n",
            "| Algorithm Type | Uses Labeled Data | Example Algorithms |\n",
            "| --- | --- | --- |\n",
            "| **Supervised Learning** | Yes | Linear Regression, Decision Trees, Random Forest, Support Vector Machines (SVM), Neural Networks |\n",
            "| **Unsupervised Learning** | No | K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA), t-Distributed Stochastic Neighbor Embedding (t-SNE), DBSCAN |\n",
            "\n",
            "**Key differences:**\n",
            "\n",
            "* **Supervised Learning**: In supervised learning, the algorithm is trained on labeled data, where the correct output is already known. The goal is to learn a mapping between inputs and outputs, so the algorithm can make predictions on new, unseen data.\n",
            "* **Unsupervised Learning**: In unsupervised learning, the algorithm is trained on unlabeled data, and the goal is to discover patterns, relationships, or groupings in the data.\n",
            "\n",
            "**Example Use Cases:**\n",
            "\n",
            "* Supervised Learning: Predicting house prices based on features like number of bedrooms, square footage, and location.\n",
            "* Unsupervised Learning: Identifying customer segments based on their purchasing behavior and demographic characteristics.\n",
            "\n",
            "**When to use each:**\n",
            "\n",
            "* Use Supervised Learning when you have labeled data and want to make predictions or classify new data.\n",
            "* Use Unsupervised Learning when you have unlabeled data and want to discover patterns, relationships, or groupings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fill_blank_prompt = \"\"\"\n",
        "Fill in the blanks using correct machine learning terms:\n",
        "\n",
        "________ learning uses labeled data.\n",
        "________ learning finds patterns in unlabeled data.\n",
        "________ learning learns by trial and error.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "7_SAAZjwvgFQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFill in the Blank Output:\\n\")\n",
        "print(run_prompt(fill_blank_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQV90oQeviRD",
        "outputId": "273608d1-e5ea-4ca5-8a5a-df389ff37b0f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fill in the Blank Output:\n",
            "\n",
            "Here are the correct machine learning terms to fill in the blanks:\n",
            "\n",
            "1. **Supervised learning** uses labeled data.\n",
            "2. **Unsupervised learning** finds patterns in unlabeled data.\n",
            "3. **Reinforcement learning** learns by trial and error.\n",
            "\n",
            "In supervised learning, the model is trained on labeled data, where the correct output is already known. In unsupervised learning, the model is trained on unlabeled data and must find patterns or structure on its own. Reinforcement learning involves a model learning by interacting with an environment and receiving rewards or penalties for its actions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgc_prompt = \"\"\"\n",
        "Role:\n",
        "You are a Machine Learning instructor.\n",
        "\n",
        "Goal:\n",
        "Explain what overfitting is.\n",
        "\n",
        "Context:\n",
        "The explanation must be simple, exam-oriented, and under 5 bullet points.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "vNLz1qJvvjyp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRGC Framework Output:\\n\")\n",
        "print(run_prompt(rgc_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBu39-6Tvlwz",
        "outputId": "7dfd3f7a-0e44-4362-9e58-d60fbf5523bc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RGC Framework Output:\n",
            "\n",
            "As a Machine Learning instructor, I'd be happy to explain overfitting in simple terms. Here are the key points:\n",
            "\n",
            "* **Overfitting**: Overfitting occurs when a machine learning model is too complex and learns the noise in the training data, rather than the underlying patterns.\n",
            "* **Reasons for overfitting**: Overfitting can happen when the model has too many parameters, the training data is small, or the model is not regularized.\n",
            "* **Consequences of overfitting**: Overfitting leads to poor performance on new, unseen data (test data). The model performs well on the training data but fails to generalize to other data.\n",
            "* **Example**: Imagine a model that learns to recognize a specific image of a cat by memorizing the exact pixels of that image. When shown a new image of a cat, the model fails to recognize it because it's too focused on the specific pixels of the original image.\n",
            "* **Solution**: Regularization techniques, such as L1 or L2 regularization, dropout, or early stopping, can help prevent overfitting by reducing the model's complexity and encouraging it to learn more general patterns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_prompt = \"\"\"\n",
        "Classify the sentiment of the following sentence:\n",
        "\n",
        "\"I love how easy this application is to use.\"\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "5JMwks-UvnWY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nZero-Shot Output:\\n\")\n",
        "print(run_prompt(zero_shot_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72AuoL_pvpJq",
        "outputId": "5dfbcd7c-4934-43f6-d23c-c33f07d34416"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Zero-Shot Output:\n",
            "\n",
            "The sentiment of the sentence \"I love how easy this application is to use\" is positive. The word \"love\" is a strong positive emotion, and the phrase \"easy to use\" is a compliment to the application, indicating satisfaction and approval.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_shot_prompt = \"\"\"\n",
        "Example:\n",
        "Sentence: \"The movie was amazing\"\n",
        "Sentiment: Positive\n",
        "\n",
        "Now classify:\n",
        "Sentence: \"The service was very slow\"\n",
        "Sentiment:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "-agF4N4ivqvk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nOne-Shot Output:\\n\")\n",
        "print(run_prompt(one_shot_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywpXpvbZvscA",
        "outputId": "122ce5d6-c922-49bb-b465-0f15a2ab7e4a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "One-Shot Output:\n",
            "\n",
            "The sentiment of the sentence \"The service was very slow\" is Negative.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = \"\"\"\n",
        "Examples:\n",
        "Sentence: \"I enjoyed the course\"\n",
        "Sentiment: Positive\n",
        "\n",
        "Sentence: \"The food was terrible\"\n",
        "Sentiment: Negative\n",
        "\n",
        "Sentence: \"The lecture was boring\"\n",
        "Sentiment: Negative\n",
        "\n",
        "Now classify:\n",
        "Sentence: \"The teacher explained concepts very clearly\"\n",
        "Sentiment:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "txImXZX4vv68"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFew-Shot Output:\\n\")\n",
        "print(run_prompt(few_shot_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok_-qVRBvxxr",
        "outputId": "96c41b37-38c4-4dbd-a253-30440fbc3d6b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Few-Shot Output:\n",
            "\n",
            "Sentence: \"The teacher explained concepts very clearly\"\n",
            "Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uKiityimvzW5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}